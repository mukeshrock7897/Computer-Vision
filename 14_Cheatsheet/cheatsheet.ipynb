{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# ğŸ“šğŸ‘ï¸ Computer Vision Interview Cheatsheet\n",
    "\n",
    "---\n",
    "\n",
    "## 1ï¸âƒ£ CV Core Pipeline (â†”ï¸ `1_CV_Core_Pipeline`) ğŸ› ï¸\n",
    "\n",
    "| ğŸ”‘ Step                   | ğŸ¯ Goal                     | ğŸ Key Imports / Functions                                                                                     | ğŸ§  Mini-Notes / Examples                                                  |\n",
    "| ------------------------- | --------------------------- | -------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------- |\n",
    "| Data Acquisition ğŸ“¥       | Load images/videos/datasets | `cv2.imread/VideoCapture`, `imageio`, `PIL.Image`, `torchvision.datasets`, `datasets` (HF)                     | Use canonical splits; cache with `symlinks`; `VideoCapture(0)` for webcam |\n",
    "| Preprocessing ğŸ§½          | Clean/format data           | `cv2.cvtColor`, `cv2.resize`, `cv2.equalizeHist`, `cv2.createCLAHE`, `cv2.GaussianBlur`, `albumentations`      | Normalize to model stats; keep aspect via letterbox; CLAHE for low-light  |\n",
    "| Feature Representation ğŸ§© | Pixels â†’ features           | `cv2.SIFT/ORB`, `skimage.feature`, `torchvision.models` (backbones), `timm`                                    | Hand-crafted vs deep features; pick backbones (ResNet, ConvNeXt, ViT)     |\n",
    "| Modeling ğŸ¤–               | Train/infer                 | `torch`, `torchvision`, `tensorflow.keras`, `ultralytics` (YOLO), `mmdetection`, `segmentation_models_pytorch` | Start with pretrain â†’ finetune; freeze â†’ unfreeze schedule                |\n",
    "| Evaluation ğŸ“Š             | Measure quality             | `sklearn.metrics`, task metrics (mAP, mIoU, Dice, PCK, MOTA, IDF1)                                             | Always compute class-wise and PR curves                                   |\n",
    "| Deployment ğŸš€             | Serve fast & safe           | `onnx`, `onnxruntime`, `tensorrt`, `openvino`, `tflite_runtime`, `fastapi`, `bentoml`                          | Quantize (INT8), batch, warmup; health probes; version models             |\n",
    "\n",
    "---\n",
    "\n",
    "## 2ï¸âƒ£ Fundamentals & Image Processing (â†”ï¸ `2_Fundamentals_ImageProcessing`) ğŸ§ª\n",
    "\n",
    "| ğŸ§© Topic                     | ğŸ Imports / Calls                                                             | ğŸ“ Notes                                                             |\n",
    "| ---------------------------- | ------------------------------------------------------------------------------ | -------------------------------------------------------------------- |\n",
    "| Digital Image Basics ğŸ§±      | `np.ndarray` (HÃ—WÃ—C), `cv2.cvtColor`                                           | BGRâ†”RGB; linear vs gamma space                                       |\n",
    "| Filtering & Denoising ğŸ§´     | `cv2.GaussianBlur`, `medianBlur`, `bilateralFilter`, `fastNlMeansDenoising`    | Gaussian (smooth), Median (salt-pepper), Bilateral (edge-preserving) |\n",
    "| Histogram & Contrast ğŸŒˆ      | `cv2.equalizeHist`, `createCLAHE`, `cv2.calcHist`                              | CLAHE for local contrast; beware color shifts                        |\n",
    "| Thresholding & Morphology ğŸ”² | `cv2.threshold`(OTSU), `adaptiveThreshold`, `cv2.erode/dilate/open/close`      | OCR/seg pipelines; remove speckles/holes                             |\n",
    "| Edge & Gradient âœ‚ï¸           | `cv2.Sobel`, `Laplacian`, `Canny`                                              | Tune hysteresis; pre-blur for stability                              |\n",
    "| Geometry & Warps ğŸ§­          | `cv2.getAffineTransform/warpAffine`, `getPerspectiveTransform/warpPerspective` | Deskew docs; rectify planes                                          |\n",
    "\n",
    "---\n",
    "\n",
    "## 3ï¸âƒ£ Programming Tools (â†”ï¸ `3_Programming_Tools`) âš™ï¸\n",
    "\n",
    "| ğŸ§° Category         | ğŸ“¦ Libs / Imports                                               | ğŸ’¡ Tip                                                |\n",
    "| ------------------- | --------------------------------------------------------------- | ----------------------------------------------------- |\n",
    "| Python Essentials   | `pathlib`, `argparse`, `itertools`, `functools.lru_cache`       | Deterministic CLIs; cache heavy ops                   |\n",
    "| CV Stacks           | `opencv-python`, `scikit-image`, `albumentations`, `imgaug`     | Albumentations for fast GPU-friendly aug              |\n",
    "| DL Frameworks       | `torch`, `torchvision`, `timm`, `tensorflow.keras`, `jax`       | `timm.create_model(\"convnext_tiny\", pretrained=True)` |\n",
    "| Industry Tools      | `onnx`, `onnxruntime`, `tensorrt`, `openvino`, `tflite_runtime` | Export once, run anywhere                             |\n",
    "| Experiment Tracking | `wandb`, `mlflow`, `tensorboard`                                | Log images/masks/PR curves                            |\n",
    "| Data Versioning     | `dvc`, `git-lfs`                                                | Reproducible datasets                                 |\n",
    "\n",
    "---\n",
    "\n",
    "## 4ï¸âƒ£ Classical CV (â†”ï¸ `4_Classical_CV`) ğŸ”\n",
    "\n",
    "| ğŸ¯ Topic               | ğŸ API / Function                                                             | ğŸ§  Notes                                            |\n",
    "| ---------------------- | ----------------------------------------------------------------------------- | --------------------------------------------------- |\n",
    "| Edges & Contours       | `cv2.Canny`, `cv2.findContours`, `cv2.HoughLines/ Circles`                    | Pre-blur; contour hierarchy                         |\n",
    "| Feature Detect & Match | `cv2.SIFT/SURF/ORB/FAST/BRISK`, `cv2.BFMatcher`, `cv2.FlannBasedMatcher`      | SIFT robust; ORB fast/free; ratio test + RANSAC     |\n",
    "| Geometry & Camera      | `cv2.calibrateCamera`, `cv2.findHomography(RANSAC)`, `cv2.solvePnP`           | Intrinsics/extrinsics; planar homography            |\n",
    "| Motion Analysis        | `cv2.calcOpticalFlowPyrLK`, `Farneback`, `cv2.createBackgroundSubtractorMOG2` | LK sparse; Farneback dense; bg subtraction for CCTV |\n",
    "\n",
    "---\n",
    "\n",
    "## 5ï¸âƒ£ ML in CV (â†”ï¸ `5_ML_in_CV`) ğŸ§®\n",
    "\n",
    "| ğŸ“¦ Model      | ğŸ Import                                                   | âœ… Use-case            | âš ï¸ Note          |\n",
    "| ------------- | ----------------------------------------------------------- | --------------------- | ---------------- |\n",
    "| KNN / SVM     | `sklearn.neighbors.KNeighborsClassifier`, `sklearn.svm.SVC` | Small deep features   | Scale features   |\n",
    "| Logistic / RF | `LogisticRegression`, `RandomForestClassifier`              | Image-level cls       | Strong baselines |\n",
    "| HOG + SVM     | `skimage.feature.hog` + SVM                                 | Pedestrian detectors  | Pre-DL classic   |\n",
    "| GMM / K-Means | `GaussianMixture`, `KMeans`                                 | Color/texture cluster | Weak supervision |\n",
    "\n",
    "---\n",
    "\n",
    "## 6ï¸âƒ£ Deep Learning Foundations (â†”ï¸ `6_DeepLearning_Foundations`) ğŸ§±ğŸ”¥\n",
    "\n",
    "| ğŸ§  Family        | ğŸ Import / Layer                                                  | ğŸ“Œ Use             | ğŸ’¡ Notes                                |\n",
    "| ---------------- | ------------------------------------------------------------------ | ------------------ | --------------------------------------- |\n",
    "| CNN Basics       | `torch.nn.Conv2d`, `BatchNorm2d`, `MaxPool2d`                      | Universal vision   | Use residuals/SE blocks                 |\n",
    "| Advanced CNNs    | `torchvision.models` (ResNet, EfficientNet, ConvNeXt), `timm`      | Backbones          | ConvNeXt/EfficientNet strong trade-offs |\n",
    "| Regularization   | `Dropout2d`, `LabelSmoothing`, `Mixup/CutMix` (`timm.data`)        | Generalization     | Mixup + cosine LR = solid               |\n",
    "| Schedulers/Optim | `AdamW`, `SGD(momentum)`, `OneCycleLR`, `CosineAnnealingLR`        | Stable training    | Warmup matters                          |\n",
    "| Video Models     | `pytorchvideo`, `torchvision.models.video` (R3D, MC3), Timesformer | Action rec, events | 3D Conv, factorized time                |\n",
    "| Checkpointing    | `torch.utils.checkpoint`                                           | Memory             | Trade compute for RAM                   |\n",
    "\n",
    "---\n",
    "\n",
    "## 7ï¸âƒ£ Detection & Localization (â†”ï¸ `7_Detection_Localization`) ğŸ¯\n",
    "\n",
    "| ğŸ” Task                | ğŸ Stack                                                               | ğŸ“ Metric             | ğŸ§  Key Points                                           |\n",
    "| ---------------------- | ---------------------------------------------------------------------- | --------------------- | ------------------------------------------------------- |\n",
    "| Bounding-Box Detectors | YOLOv5/8 (`ultralytics`), `mmdetection` (Faster-RCNN, RetinaNet, FCOS) | mAP@[.5:.95], latency | Augs (mosaic), anchors vs anchor-free, NMS/Soft-NMS/WBF |\n",
    "| Keypoints / Pose       | `mmpose`, `torchvision.models.detection.keypointrcnn_resnet50_fpn`     | PCK/OKS               | Person/hand/face landmarks; heatmaps                    |\n",
    "| Tracking               | SORT/DeepSORT/ByteTrack/OC-SORT (`pip` pkgs)                           | MOTA, IDF1, HOTA      | Re-ID embeddings boost IDF1; occlusion handling         |\n",
    "\n",
    "---\n",
    "\n",
    "## 8ï¸âƒ£ Segmentation (â†”ï¸ `8_Segmentation`) ğŸ§µ\n",
    "\n",
    "| ğŸ§µ Type   | ğŸ Models / Libs                                                   | ğŸ“ Metrics  | ğŸ“ Notes                  |\n",
    "| --------- | ------------------------------------------------------------------ | ----------- | ------------------------- |\n",
    "| Semantic  | `segmentation_models_pytorch` (UNet, DeepLabv3+), `mmsegmentation` | mIoU, FWIoU | Class mask per pixel      |\n",
    "| Instance  | `Mask R-CNN`, `Detectron2`, `mmdet`                                | AP^mask     | Boxes + masks             |\n",
    "| Panoptic  | `Panoptic FPN`, `Mask2Former`                                      | PQ          | Unified thing+stuff       |\n",
    "| Post-proc | `cv2.morphologyEx`, CRF (densecrf)                                 | â€”           | Clean edges, remove noise |\n",
    "\n",
    "---\n",
    "\n",
    "## 9ï¸âƒ£ Generative Vision (â†”ï¸ `9_Generative_Vision`) ğŸ§ªğŸ¨\n",
    "\n",
    "| ğŸŒˆ Model                                  | ğŸ Tools                                        | ğŸ“Œ Use                      | ğŸ’¡ Notes                              |\n",
    "| ----------------------------------------- | ----------------------------------------------- | --------------------------- | ------------------------------------- |\n",
    "| GANs (DCGAN, CycleGAN, Pix2Pix, StyleGAN) | `torch`, `keras`, `pytorch-gan` repos           | Synthesis, translation      | Instability â†’ use spectral norm, TTUR |\n",
    "| Diffusion (DDPM, Latent, ControlNet)      | `diffusers` (HF)                                | Inpainting, SR, text-to-img | Guidance scale, LoRA finetune         |\n",
    "| Vision Transformers                       | `timm` (ViT, Swin), `detectron2`/`mmdet` (DETR) | Global context              | Patch size & window attention         |\n",
    "| Self-Supervised                           | `lightly`, `solo-learn`, `timm` (DINO), MAE     | Pretrain without labels     | Freeze backbone + linear probe        |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”Ÿ Multimodal & 3D (â†”ï¸ `10_Multimodal_3D_Vision`) ğŸ§©\n",
    "\n",
    "| ğŸ§­ Area              | ğŸ Stack                                                                    | ğŸ“ Metric    | ğŸ§  Notes                         |\n",
    "| -------------------- | --------------------------------------------------------------------------- | ------------ | -------------------------------- |\n",
    "| Vision-Language      | CLIP (`open_clip_pytorch`), BLIP/LLaVA (`transformers`)                     | Recall@k     | Zero-shot retrieval, captioning  |\n",
    "| 3D Recon (SfM/MVS)   | COLMAP (CLI), `open3d`, `kornia`                                            | Reproj error | From images â†’ point clouds/mesh  |\n",
    "| NeRF                 | `nerfstudio`, `instant-ngp`                                                 | PSNR/SSIM    | Radiance fields; view synth      |\n",
    "| Point Clouds / LiDAR | `open3d`, `mmdetection3d`, `torch-points3d` (PointNet++, KPConv, Minkowski) | mAP3D/IoU3D  | Voxel vs point ops, sparse convs |\n",
    "\n",
    "---\n",
    "\n",
    "## 1ï¸âƒ£1ï¸âƒ£ Real-Time & Embedded CV (â†”ï¸ `11_RealTime_Embedded_CV`) âš¡ğŸ“±\n",
    "\n",
    "| âš™ï¸ Topic       | ğŸ§° Tooling                                                          | ğŸ’¡ Practical Tips                          |\n",
    "| -------------- | ------------------------------------------------------------------- | ------------------------------------------ |\n",
    "| Optimization   | `onnxruntime`(EP=CUDA, TensorRT), `tensorrt`, `openvino`, `tflite`  | INT8 PTQ/QAT, layer fusion, dynamic shapes |\n",
    "| Edge AI        | Jetson (`jetson-inference`), Coral (`edgetpu`), iOS (`coremltools`) | Keep memory small; measure end-to-end      |\n",
    "| Video Pipeline | `opencv` + `GStreamer`, `decord`                                    | Decode on GPU; parallel I/O threads        |\n",
    "| Throughput     | batching, `torch.compile`, CUDA Graphs                              | Prefill warmup; pin memory; async H2D      |\n",
    "| Scheduling     | `ray`, `tritonserver` (NVIDIA)                                      | Multi-model, model repo versioning         |\n",
    "\n",
    "---\n",
    "\n",
    "## 1ï¸âƒ£2ï¸âƒ£ Advanced Applications (â†”ï¸ `12_Advanced_Applications`) ğŸ§©\n",
    "\n",
    "| ğŸ§© App             | ğŸ Stack                                               | ğŸ§  Notes                             |\n",
    "| ------------------ | ------------------------------------------------------ | ------------------------------------ |\n",
    "| Face Recognition   | `insightface`, ArcFace, `dlib` (align)                 | L2 on embeddings; anti-spoofing      |\n",
    "| OCR / Documents    | `paddleocr`, `Tesseract`, TrOCR/Donut (`transformers`) | Layout analysis, rotation/deskew     |\n",
    "| Augmented Reality  | `cv2.aruco`, ORB-SLAM2, `g2o`                          | Marker vs markerless; pose stability |\n",
    "| Autonomous Systems | `mmdet3d`, `nuscenes-devkit`, EKF/UKF                  | Perception stack + sensor fusion     |\n",
    "\n",
    "---\n",
    "\n",
    "## 1ï¸âƒ£3ï¸âƒ£ Ethics, Safety, Trends (â†”ï¸ `13_Ethics_Safety_Trends`) âš–ï¸\n",
    "\n",
    "| ğŸ§  Area         | ğŸ’¼ What to Do                                           | ğŸ” Tools / Ideas                 |\n",
    "| --------------- | ------------------------------------------------------- | -------------------------------- |\n",
    "| Bias & Fairness | Demographic evals; balanced sampling                    | Group metrics; stratified splits |\n",
    "| Privacy         | Blur/anonymize; on-device; FL/DP                        | `presidio`, k-anonymity, DP-SGD  |\n",
    "| Safety          | Content filters; spoof detection                        | Liveness, tamper detection       |\n",
    "| Trends          | ViT/DETR everywhere; video diffusion; multimodal agents | Keep export path (ONNX â†’ EPs)    |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ Task-Specific Metrics (Quick Grab)\n",
    "\n",
    "| Task           | Metric                  | Snippet / Note                  |\n",
    "| -------------- | ----------------------- | ------------------------------- |\n",
    "| Classification | Acc, Prec/Rec/F1, AUC   | `sklearn.metrics.*`             |\n",
    "| Detection      | mAP@[.5:.95], PR curves | COCO eval; area by size (S/M/L) |\n",
    "| Segmentation   | mIoU, Dice/F1           | Class-wise IoU; boundary F1     |\n",
    "| Keypoints      | PCK/OKS                 | Normalize by scale              |\n",
    "| Tracking       | MOTA, IDF1, HOTA        | ID consistency matters          |\n",
    "| Re-ID          | mAP, Rank-1             | CMC curves                      |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§° Python Built-ins & CV Snippets (Tiny)\n",
    "\n",
    "| ğŸ”§ Item        | âœ¨ Example                             | ğŸ’¡ Why                                        |\n",
    "| -------------- | ------------------------------------- | --------------------------------------------- |\n",
    "| Path glob      | `for p in Path(\"img\").glob(\"*.jpg\"):` | Batch I/O                                     |\n",
    "| Timing         | `time.perf_counter()`                 | Profile hot spots                             |\n",
    "| Caching        | `@lru_cache`                          | Reuse heavy ops (e.g., decode fonts)          |\n",
    "| Vectorized ops | `np.stack`, `np.pad`                  | Avoid Python loops                            |\n",
    "| Seeds          | `torch.manual_seed(42)`               | Repro runs                                    |\n",
    "| Show           | `cv2.imshow(...); cv2.waitKey(1)`     | Quick viz; donâ€™t forget `destroyAllWindows()` |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“¦ Common Datasets (Interview-friendly)\n",
    "\n",
    "| ğŸ“š Domain      | ğŸ”— Dataset             | ğŸ“ Note               |\n",
    "| -------------- | ---------------------- | --------------------- |\n",
    "| Classification | CIFAR-10/100, ImageNet | Baselines & transfers |\n",
    "| Detection      | COCO, Pascal VOC       | COCO metrics standard |\n",
    "| Segmentation   | Cityscapes, ADE20K     | Urban scenes, diverse |\n",
    "| Pose           | COCO-Keypoints, MPII   | Human landmarks       |\n",
    "| OCR            | IAM, SynthText         | Doc pipelines         |\n",
    "| 3D/AV          | KITTI, nuScenes, Waymo | Multi-sensor stacks   |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ› ï¸ Minimal PyTorch Patterns (at a glance)\n",
    "\n",
    "| ğŸ¯ Task      | ğŸ”© Pattern                                                  | ğŸ” Note                         |\n",
    "| ------------ | ----------------------------------------------------------- | ------------------------------- |\n",
    "| Finetune CLS | `timm.create_model(..., pretrained=True, num_classes=C)`    | Freezeâ†’unfreeze; AdamW + cosine |\n",
    "| Train Seg    | `segmentation_models_pytorch.Unet(encoder_name=\"resnet34\")` | Use Dice+CE combo               |\n",
    "| Export       | `torch.onnx.export(model, x, \"m.onnx\", opset_version=17)`   | Then run ORT/TensorRT           |\n",
    "| Inference    | `model.eval(); torch.no_grad()`                             | Batch + pinned memory           |\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
