{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 📚👁️ Computer Vision Interview Cheatsheet\n",
    "\n",
    "---\n",
    "\n",
    "## 1️⃣ CV Core Pipeline (↔︎ `1_CV_Core_Pipeline`) 🛠️\n",
    "\n",
    "| 🔑 Step                   | 🎯 Goal                     | 🐍 Key Imports / Functions                                                                                     | 🧠 Mini-Notes / Examples                                                  |\n",
    "| ------------------------- | --------------------------- | -------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------- |\n",
    "| Data Acquisition 📥       | Load images/videos/datasets | `cv2.imread/VideoCapture`, `imageio`, `PIL.Image`, `torchvision.datasets`, `datasets` (HF)                     | Use canonical splits; cache with `symlinks`; `VideoCapture(0)` for webcam |\n",
    "| Preprocessing 🧽          | Clean/format data           | `cv2.cvtColor`, `cv2.resize`, `cv2.equalizeHist`, `cv2.createCLAHE`, `cv2.GaussianBlur`, `albumentations`      | Normalize to model stats; keep aspect via letterbox; CLAHE for low-light  |\n",
    "| Feature Representation 🧩 | Pixels → features           | `cv2.SIFT/ORB`, `skimage.feature`, `torchvision.models` (backbones), `timm`                                    | Hand-crafted vs deep features; pick backbones (ResNet, ConvNeXt, ViT)     |\n",
    "| Modeling 🤖               | Train/infer                 | `torch`, `torchvision`, `tensorflow.keras`, `ultralytics` (YOLO), `mmdetection`, `segmentation_models_pytorch` | Start with pretrain → finetune; freeze → unfreeze schedule                |\n",
    "| Evaluation 📊             | Measure quality             | `sklearn.metrics`, task metrics (mAP, mIoU, Dice, PCK, MOTA, IDF1)                                             | Always compute class-wise and PR curves                                   |\n",
    "| Deployment 🚀             | Serve fast & safe           | `onnx`, `onnxruntime`, `tensorrt`, `openvino`, `tflite_runtime`, `fastapi`, `bentoml`                          | Quantize (INT8), batch, warmup; health probes; version models             |\n",
    "\n",
    "---\n",
    "\n",
    "## 2️⃣ Fundamentals & Image Processing (↔︎ `2_Fundamentals_ImageProcessing`) 🧪\n",
    "\n",
    "| 🧩 Topic                     | 🐍 Imports / Calls                                                             | 📝 Notes                                                             |\n",
    "| ---------------------------- | ------------------------------------------------------------------------------ | -------------------------------------------------------------------- |\n",
    "| Digital Image Basics 🧱      | `np.ndarray` (H×W×C), `cv2.cvtColor`                                           | BGR↔RGB; linear vs gamma space                                       |\n",
    "| Filtering & Denoising 🧴     | `cv2.GaussianBlur`, `medianBlur`, `bilateralFilter`, `fastNlMeansDenoising`    | Gaussian (smooth), Median (salt-pepper), Bilateral (edge-preserving) |\n",
    "| Histogram & Contrast 🌈      | `cv2.equalizeHist`, `createCLAHE`, `cv2.calcHist`                              | CLAHE for local contrast; beware color shifts                        |\n",
    "| Thresholding & Morphology 🔲 | `cv2.threshold`(OTSU), `adaptiveThreshold`, `cv2.erode/dilate/open/close`      | OCR/seg pipelines; remove speckles/holes                             |\n",
    "| Edge & Gradient ✂️           | `cv2.Sobel`, `Laplacian`, `Canny`                                              | Tune hysteresis; pre-blur for stability                              |\n",
    "| Geometry & Warps 🧭          | `cv2.getAffineTransform/warpAffine`, `getPerspectiveTransform/warpPerspective` | Deskew docs; rectify planes                                          |\n",
    "\n",
    "---\n",
    "\n",
    "## 3️⃣ Programming Tools (↔︎ `3_Programming_Tools`) ⚙️\n",
    "\n",
    "| 🧰 Category         | 📦 Libs / Imports                                               | 💡 Tip                                                |\n",
    "| ------------------- | --------------------------------------------------------------- | ----------------------------------------------------- |\n",
    "| Python Essentials   | `pathlib`, `argparse`, `itertools`, `functools.lru_cache`       | Deterministic CLIs; cache heavy ops                   |\n",
    "| CV Stacks           | `opencv-python`, `scikit-image`, `albumentations`, `imgaug`     | Albumentations for fast GPU-friendly aug              |\n",
    "| DL Frameworks       | `torch`, `torchvision`, `timm`, `tensorflow.keras`, `jax`       | `timm.create_model(\"convnext_tiny\", pretrained=True)` |\n",
    "| Industry Tools      | `onnx`, `onnxruntime`, `tensorrt`, `openvino`, `tflite_runtime` | Export once, run anywhere                             |\n",
    "| Experiment Tracking | `wandb`, `mlflow`, `tensorboard`                                | Log images/masks/PR curves                            |\n",
    "| Data Versioning     | `dvc`, `git-lfs`                                                | Reproducible datasets                                 |\n",
    "\n",
    "---\n",
    "\n",
    "## 4️⃣ Classical CV (↔︎ `4_Classical_CV`) 🔎\n",
    "\n",
    "| 🎯 Topic               | 🐍 API / Function                                                             | 🧠 Notes                                            |\n",
    "| ---------------------- | ----------------------------------------------------------------------------- | --------------------------------------------------- |\n",
    "| Edges & Contours       | `cv2.Canny`, `cv2.findContours`, `cv2.HoughLines/ Circles`                    | Pre-blur; contour hierarchy                         |\n",
    "| Feature Detect & Match | `cv2.SIFT/SURF/ORB/FAST/BRISK`, `cv2.BFMatcher`, `cv2.FlannBasedMatcher`      | SIFT robust; ORB fast/free; ratio test + RANSAC     |\n",
    "| Geometry & Camera      | `cv2.calibrateCamera`, `cv2.findHomography(RANSAC)`, `cv2.solvePnP`           | Intrinsics/extrinsics; planar homography            |\n",
    "| Motion Analysis        | `cv2.calcOpticalFlowPyrLK`, `Farneback`, `cv2.createBackgroundSubtractorMOG2` | LK sparse; Farneback dense; bg subtraction for CCTV |\n",
    "\n",
    "---\n",
    "\n",
    "## 5️⃣ ML in CV (↔︎ `5_ML_in_CV`) 🧮\n",
    "\n",
    "| 📦 Model      | 🐍 Import                                                   | ✅ Use-case            | ⚠️ Note          |\n",
    "| ------------- | ----------------------------------------------------------- | --------------------- | ---------------- |\n",
    "| KNN / SVM     | `sklearn.neighbors.KNeighborsClassifier`, `sklearn.svm.SVC` | Small deep features   | Scale features   |\n",
    "| Logistic / RF | `LogisticRegression`, `RandomForestClassifier`              | Image-level cls       | Strong baselines |\n",
    "| HOG + SVM     | `skimage.feature.hog` + SVM                                 | Pedestrian detectors  | Pre-DL classic   |\n",
    "| GMM / K-Means | `GaussianMixture`, `KMeans`                                 | Color/texture cluster | Weak supervision |\n",
    "\n",
    "---\n",
    "\n",
    "## 6️⃣ Deep Learning Foundations (↔︎ `6_DeepLearning_Foundations`) 🧱🔥\n",
    "\n",
    "| 🧠 Family        | 🐍 Import / Layer                                                  | 📌 Use             | 💡 Notes                                |\n",
    "| ---------------- | ------------------------------------------------------------------ | ------------------ | --------------------------------------- |\n",
    "| CNN Basics       | `torch.nn.Conv2d`, `BatchNorm2d`, `MaxPool2d`                      | Universal vision   | Use residuals/SE blocks                 |\n",
    "| Advanced CNNs    | `torchvision.models` (ResNet, EfficientNet, ConvNeXt), `timm`      | Backbones          | ConvNeXt/EfficientNet strong trade-offs |\n",
    "| Regularization   | `Dropout2d`, `LabelSmoothing`, `Mixup/CutMix` (`timm.data`)        | Generalization     | Mixup + cosine LR = solid               |\n",
    "| Schedulers/Optim | `AdamW`, `SGD(momentum)`, `OneCycleLR`, `CosineAnnealingLR`        | Stable training    | Warmup matters                          |\n",
    "| Video Models     | `pytorchvideo`, `torchvision.models.video` (R3D, MC3), Timesformer | Action rec, events | 3D Conv, factorized time                |\n",
    "| Checkpointing    | `torch.utils.checkpoint`                                           | Memory             | Trade compute for RAM                   |\n",
    "\n",
    "---\n",
    "\n",
    "## 7️⃣ Detection & Localization (↔︎ `7_Detection_Localization`) 🎯\n",
    "\n",
    "| 🔍 Task                | 🐍 Stack                                                               | 📏 Metric             | 🧠 Key Points                                           |\n",
    "| ---------------------- | ---------------------------------------------------------------------- | --------------------- | ------------------------------------------------------- |\n",
    "| Bounding-Box Detectors | YOLOv5/8 (`ultralytics`), `mmdetection` (Faster-RCNN, RetinaNet, FCOS) | mAP@[.5:.95], latency | Augs (mosaic), anchors vs anchor-free, NMS/Soft-NMS/WBF |\n",
    "| Keypoints / Pose       | `mmpose`, `torchvision.models.detection.keypointrcnn_resnet50_fpn`     | PCK/OKS               | Person/hand/face landmarks; heatmaps                    |\n",
    "| Tracking               | SORT/DeepSORT/ByteTrack/OC-SORT (`pip` pkgs)                           | MOTA, IDF1, HOTA      | Re-ID embeddings boost IDF1; occlusion handling         |\n",
    "\n",
    "---\n",
    "\n",
    "## 8️⃣ Segmentation (↔︎ `8_Segmentation`) 🧵\n",
    "\n",
    "| 🧵 Type   | 🐍 Models / Libs                                                   | 📏 Metrics  | 📝 Notes                  |\n",
    "| --------- | ------------------------------------------------------------------ | ----------- | ------------------------- |\n",
    "| Semantic  | `segmentation_models_pytorch` (UNet, DeepLabv3+), `mmsegmentation` | mIoU, FWIoU | Class mask per pixel      |\n",
    "| Instance  | `Mask R-CNN`, `Detectron2`, `mmdet`                                | AP^mask     | Boxes + masks             |\n",
    "| Panoptic  | `Panoptic FPN`, `Mask2Former`                                      | PQ          | Unified thing+stuff       |\n",
    "| Post-proc | `cv2.morphologyEx`, CRF (densecrf)                                 | —           | Clean edges, remove noise |\n",
    "\n",
    "---\n",
    "\n",
    "## 9️⃣ Generative Vision (↔︎ `9_Generative_Vision`) 🧪🎨\n",
    "\n",
    "| 🌈 Model                                  | 🐍 Tools                                        | 📌 Use                      | 💡 Notes                              |\n",
    "| ----------------------------------------- | ----------------------------------------------- | --------------------------- | ------------------------------------- |\n",
    "| GANs (DCGAN, CycleGAN, Pix2Pix, StyleGAN) | `torch`, `keras`, `pytorch-gan` repos           | Synthesis, translation      | Instability → use spectral norm, TTUR |\n",
    "| Diffusion (DDPM, Latent, ControlNet)      | `diffusers` (HF)                                | Inpainting, SR, text-to-img | Guidance scale, LoRA finetune         |\n",
    "| Vision Transformers                       | `timm` (ViT, Swin), `detectron2`/`mmdet` (DETR) | Global context              | Patch size & window attention         |\n",
    "| Self-Supervised                           | `lightly`, `solo-learn`, `timm` (DINO), MAE     | Pretrain without labels     | Freeze backbone + linear probe        |\n",
    "\n",
    "---\n",
    "\n",
    "## 🔟 Multimodal & 3D (↔︎ `10_Multimodal_3D_Vision`) 🧩\n",
    "\n",
    "| 🧭 Area              | 🐍 Stack                                                                    | 📏 Metric    | 🧠 Notes                         |\n",
    "| -------------------- | --------------------------------------------------------------------------- | ------------ | -------------------------------- |\n",
    "| Vision-Language      | CLIP (`open_clip_pytorch`), BLIP/LLaVA (`transformers`)                     | Recall@k     | Zero-shot retrieval, captioning  |\n",
    "| 3D Recon (SfM/MVS)   | COLMAP (CLI), `open3d`, `kornia`                                            | Reproj error | From images → point clouds/mesh  |\n",
    "| NeRF                 | `nerfstudio`, `instant-ngp`                                                 | PSNR/SSIM    | Radiance fields; view synth      |\n",
    "| Point Clouds / LiDAR | `open3d`, `mmdetection3d`, `torch-points3d` (PointNet++, KPConv, Minkowski) | mAP3D/IoU3D  | Voxel vs point ops, sparse convs |\n",
    "\n",
    "---\n",
    "\n",
    "## 1️⃣1️⃣ Real-Time & Embedded CV (↔︎ `11_RealTime_Embedded_CV`) ⚡📱\n",
    "\n",
    "| ⚙️ Topic       | 🧰 Tooling                                                          | 💡 Practical Tips                          |\n",
    "| -------------- | ------------------------------------------------------------------- | ------------------------------------------ |\n",
    "| Optimization   | `onnxruntime`(EP=CUDA, TensorRT), `tensorrt`, `openvino`, `tflite`  | INT8 PTQ/QAT, layer fusion, dynamic shapes |\n",
    "| Edge AI        | Jetson (`jetson-inference`), Coral (`edgetpu`), iOS (`coremltools`) | Keep memory small; measure end-to-end      |\n",
    "| Video Pipeline | `opencv` + `GStreamer`, `decord`                                    | Decode on GPU; parallel I/O threads        |\n",
    "| Throughput     | batching, `torch.compile`, CUDA Graphs                              | Prefill warmup; pin memory; async H2D      |\n",
    "| Scheduling     | `ray`, `tritonserver` (NVIDIA)                                      | Multi-model, model repo versioning         |\n",
    "\n",
    "---\n",
    "\n",
    "## 1️⃣2️⃣ Advanced Applications (↔︎ `12_Advanced_Applications`) 🧩\n",
    "\n",
    "| 🧩 App             | 🐍 Stack                                               | 🧠 Notes                             |\n",
    "| ------------------ | ------------------------------------------------------ | ------------------------------------ |\n",
    "| Face Recognition   | `insightface`, ArcFace, `dlib` (align)                 | L2 on embeddings; anti-spoofing      |\n",
    "| OCR / Documents    | `paddleocr`, `Tesseract`, TrOCR/Donut (`transformers`) | Layout analysis, rotation/deskew     |\n",
    "| Augmented Reality  | `cv2.aruco`, ORB-SLAM2, `g2o`                          | Marker vs markerless; pose stability |\n",
    "| Autonomous Systems | `mmdet3d`, `nuscenes-devkit`, EKF/UKF                  | Perception stack + sensor fusion     |\n",
    "\n",
    "---\n",
    "\n",
    "## 1️⃣3️⃣ Ethics, Safety, Trends (↔︎ `13_Ethics_Safety_Trends`) ⚖️\n",
    "\n",
    "| 🧠 Area         | 💼 What to Do                                           | 🔐 Tools / Ideas                 |\n",
    "| --------------- | ------------------------------------------------------- | -------------------------------- |\n",
    "| Bias & Fairness | Demographic evals; balanced sampling                    | Group metrics; stratified splits |\n",
    "| Privacy         | Blur/anonymize; on-device; FL/DP                        | `presidio`, k-anonymity, DP-SGD  |\n",
    "| Safety          | Content filters; spoof detection                        | Liveness, tamper detection       |\n",
    "| Trends          | ViT/DETR everywhere; video diffusion; multimodal agents | Keep export path (ONNX → EPs)    |\n",
    "\n",
    "---\n",
    "\n",
    "## 📏 Task-Specific Metrics (Quick Grab)\n",
    "\n",
    "| Task           | Metric                  | Snippet / Note                  |\n",
    "| -------------- | ----------------------- | ------------------------------- |\n",
    "| Classification | Acc, Prec/Rec/F1, AUC   | `sklearn.metrics.*`             |\n",
    "| Detection      | mAP@[.5:.95], PR curves | COCO eval; area by size (S/M/L) |\n",
    "| Segmentation   | mIoU, Dice/F1           | Class-wise IoU; boundary F1     |\n",
    "| Keypoints      | PCK/OKS                 | Normalize by scale              |\n",
    "| Tracking       | MOTA, IDF1, HOTA        | ID consistency matters          |\n",
    "| Re-ID          | mAP, Rank-1             | CMC curves                      |\n",
    "\n",
    "---\n",
    "\n",
    "## 🧰 Python Built-ins & CV Snippets (Tiny)\n",
    "\n",
    "| 🔧 Item        | ✨ Example                             | 💡 Why                                        |\n",
    "| -------------- | ------------------------------------- | --------------------------------------------- |\n",
    "| Path glob      | `for p in Path(\"img\").glob(\"*.jpg\"):` | Batch I/O                                     |\n",
    "| Timing         | `time.perf_counter()`                 | Profile hot spots                             |\n",
    "| Caching        | `@lru_cache`                          | Reuse heavy ops (e.g., decode fonts)          |\n",
    "| Vectorized ops | `np.stack`, `np.pad`                  | Avoid Python loops                            |\n",
    "| Seeds          | `torch.manual_seed(42)`               | Repro runs                                    |\n",
    "| Show           | `cv2.imshow(...); cv2.waitKey(1)`     | Quick viz; don’t forget `destroyAllWindows()` |\n",
    "\n",
    "---\n",
    "\n",
    "## 📦 Common Datasets (Interview-friendly)\n",
    "\n",
    "| 📚 Domain      | 🔗 Dataset             | 📝 Note               |\n",
    "| -------------- | ---------------------- | --------------------- |\n",
    "| Classification | CIFAR-10/100, ImageNet | Baselines & transfers |\n",
    "| Detection      | COCO, Pascal VOC       | COCO metrics standard |\n",
    "| Segmentation   | Cityscapes, ADE20K     | Urban scenes, diverse |\n",
    "| Pose           | COCO-Keypoints, MPII   | Human landmarks       |\n",
    "| OCR            | IAM, SynthText         | Doc pipelines         |\n",
    "| 3D/AV          | KITTI, nuScenes, Waymo | Multi-sensor stacks   |\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ Minimal PyTorch Patterns (at a glance)\n",
    "\n",
    "| 🎯 Task      | 🔩 Pattern                                                  | 🔎 Note                         |\n",
    "| ------------ | ----------------------------------------------------------- | ------------------------------- |\n",
    "| Finetune CLS | `timm.create_model(..., pretrained=True, num_classes=C)`    | Freeze→unfreeze; AdamW + cosine |\n",
    "| Train Seg    | `segmentation_models_pytorch.Unet(encoder_name=\"resnet34\")` | Use Dice+CE combo               |\n",
    "| Export       | `torch.onnx.export(model, x, \"m.onnx\", opset_version=17)`   | Then run ORT/TensorRT           |\n",
    "| Inference    | `model.eval(); torch.no_grad()`                             | Batch + pinned memory           |\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
