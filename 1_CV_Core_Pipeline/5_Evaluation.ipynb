{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“ Evaluation in Computer Vision\n",
    "\n",
    "## ğŸ¯ Intent\n",
    "\n",
    "Measure how well a model ğŸ§  performs on image/video tasks ğŸ–¼ï¸ğŸ¥.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Œ Metrics\n",
    "\n",
    "* âœ… **Accuracy** â†’ overall correctness (good for classification)\n",
    "* ğŸ¯ **Precision / Recall** â†’ balance false positives & false negatives\n",
    "* âš–ï¸ **F1-Score** â†’ harmonic mean of precision & recall\n",
    "* ğŸ“ **IoU (Intersection over Union)** â†’ overlap of predicted vs. true boxes (detection/segmentation)\n",
    "* ğŸ† **mAP (mean Average Precision)** â†’ gold standard for object detection\n",
    "* âš¡ **FPS (Frames per Second)** â†’ speed for real-time systems\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Quick Summary\n",
    "\n",
    "* ğŸ‘‰ Pick metrics based on **task** (classification vs detection vs segmentation)\n",
    "* ğŸ‘‰ IoU & mAP = essential for bounding box tasks ğŸ¯\n",
    "* ğŸ‘‰ Accuracy alone is not enough in CV ğŸš«\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
